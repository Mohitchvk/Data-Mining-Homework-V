{"cells":[{"cell_type":"markdown","metadata":{"id":"Yq0XoVUIVNLC"},"source":["# Homework 5"]},{"cell_type":"markdown","metadata":{"id":"0aqF485OxR-U"},"source":["**Before you start:** Read Chapter on Naive Bayes and KNN in the textbook.\n","\n","**Note:** Please enter the code along with your comments in the **TODO** section.\n","\n","Alternative solutions are always welcomed."]},{"cell_type":"markdown","metadata":{"id":"Rion40Hwnf-B"},"source":["# Part 1: K-Nearst-Neighbors"]},{"cell_type":"markdown","metadata":{"id":"6X-yZb6YvfhH"},"source":["### Problem 2 ##"]},{"cell_type":"markdown","metadata":{"id":"1hgf-yTV9q2V"},"source":["The objective is to classify the breast cancer data using K-NN classifier."]},{"cell_type":"markdown","metadata":{"id":"7zY4oMVmBMHg"},"source":["**TODO1**\n","\n","Load the breast cancer data and rename the columns to the below fields in the same order\n","\n","Id, C_thickness, Cell_Size, Cell_Shape, Adhesion, E_Cell_Size, Bare_Nuclei, B_Chromatin, N_Nucleoli, Mitoses, Class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1kVAjSQpZYiJ"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"oSlUegOdcT2I"},"source":["**TODO 2**\n","\n","Plot the heatmap for the correlation coefficients with the target variable (Class)  and interpret your findings.\n","\n","\n","Drop redundant columns and view summary of the dataset.\n","Convert all the variables to numeric.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6GyYUSKkfjXG"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"2saGofKTEpiJ"},"source":["**TODO 3**\n","\n","\n","\n","Considering the fundamental idea of k-NN, would you recommend data rescaling before model building? Why? \n","\n","If so, partition the data into 75% training and 25% validation set.\n","\n","Impute the missing values with the mean values of training data.\n","Check if all the nulls are removed in both train and test dataset.\n","\n","Standardize the data.\n","\n","**Note:**   When you standardize the validation set, you need to use the training set's mean and variance. \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mizcZxd1fips"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"RrGgm_3mJbIR"},"source":["**TODO 4**\n","\n","Choose the best k from 1-10 based on the classification accuracy of different k values on the validation set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lgT0rqC4fOAp"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"p7nvr1AbXeMg"},"source":["**TODO 5**\n","\n","For the chosen k, display the confusion matrix and evaluate the performance of the model using recall and precision.\n","\n","Check for overfitting and underfitting for the k chosen."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UANl3XmTfPjZ"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"rvUBy4oPMMIf"},"source":["**TODO 6**\n","\n","Classify the new record given below using the chosen k. \n","\n","1002945, 5, 4, 4, 5, 7, 10, 3, 2, 1\n","\n","Considering the size of the dataset, would you recommend data partition before scoring the new record? Why?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NtThVQwSfhow"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"XvDQjUmNSuLZ"},"source":["### Problem 3 ##"]},{"cell_type":"markdown","metadata":{"id":"96_tZKmHSuLZ"},"source":["The data concerns city-cycle fuel consumption in miles per gallon (mpg). The objective is to use k-NN regression to predict the mpg with the given attributes."]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"viZfphuao7EV"},"outputs":[],"source":["# import the dataset \"auto_mpg.csv\"\n","df=pd.read_csv(\"auto_mpg.csv\")"]},{"cell_type":"markdown","metadata":{"id":"H2OO76SGo7EV"},"source":["**TODO 1**\n","\n","Check the unique value of the variable \"car name\". \n","\n","Would you recommend keeping \"car name\" for prediction? Why? \n","\n","If not, eliminate the variable \"car name\"."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"05R9WLrTpijX"},"outputs":[{"data":{"text/plain":["Index(['mpg', 'cylinders', 'displacement', 'horsepower', 'weight',\n","       'acceleration', 'model year', 'origin', 'car name'],\n","      dtype='object')"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["df.columns"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Unique Count of the variable car name:  301\n","Length of the Dataset:  393\n"]}],"source":["print(\"Unique Count of the variable car name: \",len(df['car name'].unique()))\n","print(\"Length of the Dataset: \",len(df))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Here, we can see that almost all the values are unique except a few. So, keeping this column does not serve any purpose to the model. So its better to drop the predictor variable help in reducing the complexity of the model.  \n","\n","Using One Hot encoding will impart 301 additional columns and  label encoding this nominal variable will bias the model by adding weight to the value."]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["df.drop('car name', axis=1, inplace=True)"]},{"cell_type":"markdown","metadata":{"id":"H8XjK4Fro7EW"},"source":["**TODO 2**\n","\n","Convert the variable \"origin\" to dummy variables before modeling"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"FnkWQelTpkZI"},"outputs":[],"source":["df = pd.get_dummies(df, columns=[\"origin\"])"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>mpg</th>\n","      <th>cylinders</th>\n","      <th>displacement</th>\n","      <th>horsepower</th>\n","      <th>weight</th>\n","      <th>acceleration</th>\n","      <th>model year</th>\n","      <th>origin_1</th>\n","      <th>origin_2</th>\n","      <th>origin_3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>18.0</td>\n","      <td>8</td>\n","      <td>307.0</td>\n","      <td>130</td>\n","      <td>3504</td>\n","      <td>12.0</td>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>15.0</td>\n","      <td>8</td>\n","      <td>350.0</td>\n","      <td>165</td>\n","      <td>3693</td>\n","      <td>11.5</td>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>18.0</td>\n","      <td>8</td>\n","      <td>318.0</td>\n","      <td>150</td>\n","      <td>3436</td>\n","      <td>11.0</td>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>16.0</td>\n","      <td>8</td>\n","      <td>304.0</td>\n","      <td>150</td>\n","      <td>3433</td>\n","      <td>12.0</td>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>17.0</td>\n","      <td>8</td>\n","      <td>302.0</td>\n","      <td>140</td>\n","      <td>3449</td>\n","      <td>10.5</td>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>388</th>\n","      <td>27.0</td>\n","      <td>4</td>\n","      <td>140.0</td>\n","      <td>86</td>\n","      <td>2790</td>\n","      <td>15.6</td>\n","      <td>82</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>389</th>\n","      <td>44.0</td>\n","      <td>4</td>\n","      <td>97.0</td>\n","      <td>52</td>\n","      <td>2130</td>\n","      <td>24.6</td>\n","      <td>82</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>390</th>\n","      <td>32.0</td>\n","      <td>4</td>\n","      <td>135.0</td>\n","      <td>84</td>\n","      <td>2295</td>\n","      <td>11.6</td>\n","      <td>82</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>391</th>\n","      <td>28.0</td>\n","      <td>4</td>\n","      <td>120.0</td>\n","      <td>79</td>\n","      <td>2625</td>\n","      <td>18.6</td>\n","      <td>82</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>392</th>\n","      <td>31.0</td>\n","      <td>4</td>\n","      <td>119.0</td>\n","      <td>82</td>\n","      <td>2720</td>\n","      <td>19.4</td>\n","      <td>82</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>393 rows Ã— 10 columns</p>\n","</div>"],"text/plain":["      mpg  cylinders  displacement horsepower  weight  acceleration  \\\n","0    18.0          8         307.0        130    3504          12.0   \n","1    15.0          8         350.0        165    3693          11.5   \n","2    18.0          8         318.0        150    3436          11.0   \n","3    16.0          8         304.0        150    3433          12.0   \n","4    17.0          8         302.0        140    3449          10.5   \n","..    ...        ...           ...        ...     ...           ...   \n","388  27.0          4         140.0         86    2790          15.6   \n","389  44.0          4          97.0         52    2130          24.6   \n","390  32.0          4         135.0         84    2295          11.6   \n","391  28.0          4         120.0         79    2625          18.6   \n","392  31.0          4         119.0         82    2720          19.4   \n","\n","     model year  origin_1  origin_2  origin_3  \n","0            70         1         0         0  \n","1            70         1         0         0  \n","2            70         1         0         0  \n","3            70         1         0         0  \n","4            70         1         0         0  \n","..          ...       ...       ...       ...  \n","388          82         1         0         0  \n","389          82         0         1         0  \n","390          82         1         0         0  \n","391          82         1         0         0  \n","392          82         1         0         0  \n","\n","[393 rows x 10 columns]"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"markdown","metadata":{"id":"NNx7iZ2aC8h1"},"source":["**TODO 3**\n","\n","Partition the data into 75% training and 25% validation set."]},{"cell_type":"code","execution_count":21,"metadata":{"id":"CGAWagCrDGDA"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","x_train, x_valid, y_train, y_valid = train_test_split(\n","    df.drop(\"mpg\", axis=1), df[\"mpg\"], test_size=0.25)\n"]},{"cell_type":"markdown","metadata":{"id":"gcjzpN38o7EY"},"source":["**TODO 4**\n","\n","Rescale the numeric data. Note that dummy variables should not be rescaled.\n","\n","**Note:** When you standardize the validation set, you need to use the training set's mean and variance."]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# There is an '?' in the data so replacing it with zero to avoid computational errors\n","x_train['horsepower'] = x_train['horsepower'].replace('?', 0)\n","x_valid['horsepower'] = x_valid['horsepower'].replace('?', 0)\n"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","\n","X_train_scaled = scaler.fit_transform(x_train.iloc[:,:-3])"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","\n","# dropping dummies and scaling rest of data\n","X_train_scaled = scaler.fit_transform(x_train.iloc[:,:-3])\n","# adding back the dummies\n","x_train_last_two_cols = x_train.iloc[:, -3:].reset_index(drop=True)\n","X_train_scaled = pd.concat([pd.DataFrame(X_train_scaled, columns=x_train.iloc[:,:-3].columns), x_train_last_two_cols], axis=1)\n","\n","# dropping dummies and scaling rest of data\n","# using the same fitted scaler used for training data to traansform\n","X_valid_scaled = scaler.transform(x_valid.iloc[:,:-3])\n","# adding back the dummies\n","x_valid_last_two_cols = x_valid.iloc[:, -3:].reset_index(drop=True)\n","X_valid_scaled = pd.concat([pd.DataFrame(X_valid_scaled,columns=x_train.iloc[:,:-3].columns),x_valid_last_two_cols], axis=1)"]},{"cell_type":"markdown","metadata":{"id":"ezvy0kvYo7EZ"},"source":["**TODO 5**\n","\n","Choose the best k from 1-10 based on the MSE of different k values on the validation set. Explain the reason for your choice."]},{"cell_type":"code","execution_count":25,"metadata":{"id":"Agdd1CYPp2rC"},"outputs":[{"name":"stdout","output_type":"stream","text":["MSE for different k values:\n","k = 1 : MSE = 11.027878787878786\n","k = 2 : MSE = 10.62027777777778\n","k = 3 : MSE = 9.876172839506175\n","k = 4 : MSE = 10.007487373737375\n","k = 5 : MSE = 10.15019393939394\n","k = 6 : MSE = 9.87452861952862\n","k = 7 : MSE = 10.146703772418059\n","k = 8 : MSE = 10.405814393939393\n","k = 9 : MSE = 10.896353660057363\n","k = 10 : MSE = 11.060410101010104\n","Best k value: 6\n","MSE for best k value: 9.87452861952862\n"]}],"source":["from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.metrics import mean_squared_error\n","\n","\n","k_values = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n","\n","mse_dict = {}\n","\n","for k in k_values:\n","    knn = KNeighborsRegressor(n_neighbors=k)\n","    knn.fit(X_train_scaled, y_train)\n","    y_pred = knn.predict(X_valid_scaled)\n","    mse = mean_squared_error(y_valid, y_pred)\n","    mse_dict[k] = mse\n","\n","print(\"MSE for different k values:\")\n","for k, mse in mse_dict.items():\n","    print(\"k =\", k, \": MSE =\", mse)\n","\n","best_k = min(mse_dict, key=mse_dict.get)\n","\n","print(\"Best k value:\", best_k)\n","print(\"MSE for best k value:\", mse_dict[best_k])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Here we have taken the best k value same as the k with lowest MSE value as it seems to be stable as well with the adjacent k values with around the same mse value. So the best k value we take here is 6. "]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","\n","# Plot the MSE values for each k value\n","plt.plot(list(mse_dict.keys()), list(mse_dict.values()),marker='o',)\n","\n","# Add axis labels and a title to the plot\n","plt.xlabel('k')\n","plt.ylabel('MSE')\n","plt.title('MSE for different k values')\n","\n","# Add a vertical line to indicate the best k value\n","plt.axvline(x=best_k, linestyle='--', color='red', label='Best k = {}'.format(best_k))\n","\n","# Add a legend to the plot\n","plt.legend()\n","\n","# Show the plot\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"MLdN-jMIp4-2"},"source":["**TODO 6**\n","\n","\n","Score the validation set with the best k. Comment on the model performance."]},{"cell_type":"code","execution_count":27,"metadata":{"id":"dmCunSm7p85I"},"outputs":[{"name":"stdout","output_type":"stream","text":["R2 score on the validation set: 1.0\n","MSE score on the validation set: 9.87452861952862\n","RMSE score on the validation set: 3.142376269565537\n"]}],"source":["# Train a KNN model using the best k value\n","best_knn = KNeighborsRegressor(n_neighbors=best_k)\n","best_knn.fit(X_train_scaled, y_train)\n","\n","# Use the trained model to make predictions on the validation set\n","y_pred = best_knn.predict(X_valid_scaled)\n","\n","# Compute the MSE of the predictions on the validation set\n","r2 = best_knn.score(X_valid_scaled, y_pred)\n","mse = mean_squared_error(y_valid, y_pred)\n","rmse = mean_squared_error(y_valid, y_pred, squared=False)\n","# Print the MSE score of the predictions on the validation set\n","\n","print(\"R2 score on the validation set:\", r2)\n","print(\"MSE score on the validation set:\", mse)\n","print(\"RMSE score on the validation set:\", rmse)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The R2 score here shows that the model performs very well on the validation set with a k value of 6 "]},{"cell_type":"markdown","metadata":{"id":"T5fTwsd1UKSN"},"source":["# Naive Bayes"]},{"cell_type":"markdown","metadata":{"id":"3IKYRqKtxR-N"},"source":["### **Problem 4**##"]},{"cell_type":"markdown","metadata":{"id":"H8fENJRPk7P7"},"source":["In this problem, we need to build a Naive Bayes model to classify whether a movie review is positive or negative. \n","\n","The given data is a subset of [the IMDB movie review dataset](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews).\n","\n","This might be your first time working with text mining. Therefore, the basic pre-processing steps are given below. \n","\n","**You have two major tasks:**\n","\n","* Go through the code and get to know the purpose of each preprocessing step. Summarize what a preprocessing step does when required.\n","* Build a multinomial Naive Bayes model to classify the reviews."]},{"cell_type":"code","execution_count":139,"metadata":{"id":"gsuUyuEhrcQO"},"outputs":[],"source":["# # Please remove # and run the following code if you have an error while importing the dataset\n","# !pip install --upgrade openpyxl"]},{"cell_type":"code","execution_count":140,"metadata":{"id":"C8gmUJ3n8Mir"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>One of the other reviewers has mentioned that ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I thought this was a wonderful way to spend ti...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Basically there's a family where a little boy ...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              review sentiment\n","0  One of the other reviewers has mentioned that ...  positive\n","1  A wonderful little production. <br /><br />The...  positive\n","2  I thought this was a wonderful way to spend ti...  positive\n","3  Basically there's a family where a little boy ...  negative\n","4  Petter Mattei's \"Love in the Time of Money\" is...  positive"]},"execution_count":140,"metadata":{},"output_type":"execute_result"}],"source":["# Import the dataset\n","import pandas as pd\n","# from google.colab import files\n","# file = files.upload()\n","df = pd.read_csv(\"IMDB Dataset_subset.csv\")\n","df.head()"]},{"cell_type":"code","execution_count":141,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":402,"status":"ok","timestamp":1616434292565,"user":{"displayName":"Wei Li","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBWSIyrP45L1xQ6JBkXSATlg4BOmkV28NZZ96I=s64","userId":"06017554584660737110"},"user_tz":240},"id":"ggt8c71U8MrD","outputId":"7f5ae431-5205-4812-9d73-e0060bd6c653"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\mohit\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\mohit\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":141,"metadata":{},"output_type":"execute_result"}],"source":["# Packages required for preprocessing #\n","from sklearn.feature_extraction.text import CountVectorizer\n","from nltk.stem import WordNetLemmatizer #for lemmatization\n","import re #regular expression package\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","nltk.download('wordnet')"]},{"cell_type":"code","execution_count":142,"metadata":{"id":"QMI-UZAQ9F-L"},"outputs":[],"source":["X = [row for row in df['review']] #list of reviews\n","classes = df['sentiment'] #list of true classes"]},{"cell_type":"code","execution_count":143,"metadata":{"id":"E4P3iseB_gIR"},"outputs":[],"source":["reviews = []\n","lemmatizer = WordNetLemmatizer() \n","\n","for review in range(0, len(X)):\n","    review = re.sub(r'[\\W_]', ' ', str(X[review])) \n","    review = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', review) \n","    review = re.sub(r'\\^[a-zA-Z]\\s+', ' ', review) \n","    review = re.sub(r'\\s+', ' ', review, flags=re.I) \n","    review = re.sub(r'^b\\s+', '', review) # if a review record is in bytes, the corresponding line will have a letter 'b' appended at the start)\n","    review = review.lower()\n","    review = re.sub(r'[0-9]+', '', review) \n","\n","    review = review.split()\n","    review = [lemmatizer.lemmatize(word) for word in review]\n","    review = ' '.join(review)\n","\n","    reviews.append(review)"]},{"cell_type":"markdown","metadata":{"id":"orhex-OXhkgV"},"source":["\n","**TODO 1**\n","\n","Explain the function that part 1 and part 2 achieve in the loop."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"rGnaXwAfBv8i"},"source":["The code is carrying out preprocessing of text data stored in the variable X using several techniques. \n","\n","These include removing non-alphabetic characters, numbers, and punctuation, converting all characters to lowercase, splitting the text into words, lemmatizing each word to its base form, and joining the lemmatized words into a single string. The processed reviews are then saved in the reviews list. This type of preprocessing is commonly done to prepare text data for use in machine learning models designed for text analysis, such as sentiment analysis or text classification.\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":144,"metadata":{"id":"dXexNUV9CnXZ"},"outputs":[],"source":["# Continue with pre-processing\n","vectorizer = CountVectorizer(stop_words = \"english\", max_df=0.7, min_df=5) \n","texts = vectorizer.fit_transform(reviews).toarray()  \n","vocab = vectorizer.vocabulary_ \n","vocab = sorted(vocab.items(), key = lambda x: x[1])\n","vocab = [v[0] for v in vocab]"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"nZPj-AWCC-YV"},"source":["\n","**TODO 2**\n","\n","What do \"texts\" and \"vocab\" represent? What is the relationship between them?"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"gOho20diDt6L"},"source":["\"texts\" is a matrix that shows the frequency of words used in preprocessed reviews, where each row represents a review and each column represents a word in the vocabulary. The CountVectorizer method converts the preprocessed reviews into a bag-of-words representation, where each unique word is represented by an index. \n","\n","\"vocab\" is a list of words in the vocabulary sorted by their corresponding index in \"texts\". \"texts\" and \"vocab\" are related as \"texts\" is a matrix representation of the reviews using the words in \"vocab\". Essentially, the text data is transformed into a numerical representation that can be used as input to machine learning models.\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"wkjhBNIlGFlu"},"source":["**TODO 3**\n","\n","Partition the data into 80% training and 20% validation set."]},{"cell_type":"code","execution_count":155,"metadata":{},"outputs":[],"source":["y=pd.get_dummies(df.iloc[:,-1:], drop_first=True)"]},{"cell_type":"code","execution_count":161,"metadata":{"id":"5WeDE--MGMq5"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_valid, y_train, y_valid = train_test_split(pd.DataFrame(texts), y, test_size=0.2)\n"]},{"cell_type":"markdown","metadata":{"id":"ZpGQxB2GGUzz"},"source":["**TODO 4**\n","\n","Build a multinomial Naive Bayes model on the training set."]},{"cell_type":"code","execution_count":162,"metadata":{"id":"mJGgsv-JGvga"},"outputs":[{"name":"stderr","output_type":"stream","text":["e:\\anaconda3\\envs\\mohit_chodisetti\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]},{"data":{"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"],"text/plain":["MultinomialNB()"]},"execution_count":162,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.naive_bayes import MultinomialNB\n","\n","nb_classifier = MultinomialNB()\n","nb_classifier.fit(X_train, y_train)\n"]},{"cell_type":"markdown","metadata":{"id":"zyypSMm_GzGb"},"source":["**Hint:** [Multinomial Naive Bayes with sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)"]},{"cell_type":"markdown","metadata":{"id":"vfIyk3vMGww0"},"source":["**TODO 5**\n","\n","Evaluate the model performance with the training and validation set. Comment on the model performance."]},{"cell_type":"code","execution_count":173,"metadata":{"id":"B5TyEr9pHJGt"},"outputs":[{"name":"stdout","output_type":"stream","text":["*****Evaluation on Training Data******\n","Evaluation Report\n","               precision    recall  f1-score   support\n","\n","           0       0.91      0.94      0.93      1623\n","           1       0.94      0.91      0.92      1577\n","\n","    accuracy                           0.92      3200\n","   macro avg       0.93      0.92      0.92      3200\n","weighted avg       0.93      0.92      0.92      3200\n","\n","Accuracy: 0.9246875\n","Precision: 0.9250227987652146\n","Recall: 0.9246875\n","F1-score: 0.9246553252718043\n"]}],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","\n","train_preds = nb_classifier.predict(X_train)\n","\n","train_acc = accuracy_score(y_train, train_preds)\n","train_prec = precision_score(y_train, train_preds, average='weighted')\n","train_rec = recall_score(y_train, train_preds, average='weighted')\n","train_f1 = f1_score(y_train, train_preds, average='weighted')\n","\n","print(\"*****Evaluation on Training Data******\")\n","print(\"Evaluation Report\\n\", classification_report(y_train, train_preds))\n","print(\"Accuracy:\", train_acc)\n","print(\"Precision:\", train_prec)\n","print(\"Recall:\", train_rec)\n","print(\"F1-score:\", train_f1)\n"]},{"cell_type":"code","execution_count":174,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["*****Evaluation on Validation Data******\n","Evaluation Report\n","               precision    recall  f1-score   support\n","\n","           0       0.82      0.86      0.84       404\n","           1       0.85      0.81      0.83       396\n","\n","    accuracy                           0.84       800\n","   macro avg       0.84      0.84      0.84       800\n","weighted avg       0.84      0.84      0.84       800\n","\n","Accuracy: 0.83625\n","Precision: 0.8370941176470589\n","Recall: 0.83625\n","F1-score: 0.836093976616147\n"]}],"source":["val_preds = nb_classifier.predict(X_valid)\n","\n","val_acc = accuracy_score(y_valid, val_preds)\n","val_prec = precision_score(y_valid, val_preds, average='weighted')\n","val_rec = recall_score(y_valid, val_preds, average='weighted')\n","val_f1 = f1_score(y_valid, val_preds, average='weighted')\n","print(\"*****Evaluation on Validation Data******\")\n","print(\"Evaluation Report\\n\", classification_report(y_valid, val_preds))\n","print(\"Accuracy:\", val_acc)\n","print(\"Precision:\", val_prec)\n","print(\"Recall:\", val_rec)\n","print(\"F1-score:\", val_f1)"]},{"cell_type":"markdown","metadata":{"id":"aQy7IX2xHK1-"},"source":["**Hint:** [Classification report with sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The model's performance on both the training and validation sets is commendable, with high accuracy and F1-score values. However, there is a minor decrease in performance on the validation set, implying that the model may be somewhat overfitting to the training data. While an 83.6% accuracy on the validation set is decent, the performance could be improved by experimenting with different classification algorithms or tuning the model's hyperparameters."]},{"cell_type":"markdown","metadata":{"id":"uIRgUPM8HiOK"},"source":["**If you are interested (this part is not graded):**\n","\n","Explore one or two records that were misclassified. Check the original text, vectorized text, and comment on the possible reason why the record got misclassified."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"REELGHe8IFcZ"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":["6X-yZb6YvfhH","XvDQjUmNSuLZ","3IKYRqKtxR-N"],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"}},"nbformat":4,"nbformat_minor":0}
